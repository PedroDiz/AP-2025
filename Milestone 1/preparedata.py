# -*- coding: utf-8 -*-
"""mile1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18O0Zpdrzn1q39Ce4yiZNCP-b_MtTSrHb

## Stage 0: (Optional) Mount to google drive ans imports
In a production setting, our pipeline downloads data programmatically
 from the ISIC API at runtime. However, to avoid re-downloading the entire
       dataset every time a Colab session restarts, we instead mount Google Drive here and read the cached files directly.
"""

# Import Drive
#from google.colab import output
#from google.colab import drive
#drive.mount('/content/drive')

# Standard library
import os
import time
import random
import zipfile

# Data handling
import requests
import pandas as pd
import numpy as np
from PIL import Image
from tqdm import tqdm

# PyTorch & vision
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import timm
import torchvision.transforms as transforms

# Scikit-learn metrics & utilities
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    roc_auc_score, roc_curve, f1_score,
    balanced_accuracy_score,
    precision_recall_fscore_support,
    classification_report
)

# Plotting
import matplotlib.pyplot as plt

"""## Stage 1: Data Acquisition & Exploration
- Download raw images and metadata from the ISIC API  
- Inspect dataset structure and class distribution

Load the dataset ISIC(collection 66, representative of the training set of task 3) into the *results* variable, ~11k entries
"""

base_url = "https://api.isic-archive.com/api/v2/images/search/"
params = {
    "collections": "66,67,73"
}

all_ids = []
results = []

page = 1
start = time.time()

while True:
    response = requests.get(base_url, params=params)
    data = response.json()

    # Extract image IDs
    for result in data.get("results", []):
        all_ids.append(result["isic_id"])
        results.append(result)

    # Next page
    next_cursor = data.get("next")
    if not next_cursor:
        break

    # Update URL for the next request
    base_url = next_cursor
    params = {}
    page += 1

elapsed = time.time() - start
print(f"Total images collected: {len(all_ids)}")
print(f"Took {elapsed:.1f} seconds")

"""Inspecting a single record to understand its structure and contents"""

results[5]

"""**We will confirm if every image is in the expected size (600x450)**"""

# Verify that all images are 600×450 pixels(Expected size)
mismatch_count = 0

for entry in results:
    try:
        x = entry["metadata"]["acquisition"]["pixels_x"]
        y = entry["metadata"]["acquisition"]["pixels_y"]
        if (x, y) != (600, 450):
            print(f"Image {entry['isic_id']} has size {x}×{y}, expected 600×450")
            mismatch_count += 1
    except KeyError:
        print(f"Image {entry.get('isic_id', 'UNKNOWN')} is missing pixel metadata.")
        mismatch_count += 1

if mismatch_count == 0:
    print("All images are confirmed to be 600×450 pixels.")
else:
    print(f"Found {mismatch_count} image(s) with unexpected dimensions or missing data.")

"""Download the photos into ISIC_IMAGES_TASK_3 folder"""

import os
import zipfile
import urllib.request
import time

# Start timing
total_start = time.time()

# Target folder
PATH = "ISIC_IMAGES_TASK_3"
os.makedirs(PATH, exist_ok=True)

# Base URL for raw GitHub content
base_url = "https://github.com/PedroDiz/AP-2025/raw/main/"

# List of ZIP file names
zip_files = [
    "ISIC_IMAGES_TASK_3_PART_1.zip",
    "ISIC_IMAGES_TASK_3_PART_2.zip",
    "ISIC_IMAGES_TASK_3_PART_3.zip"
]

# Download and extract each ZIP file
for zip_file in zip_files:
    start = time.time()

    zip_path = os.path.join(os.getcwd(), zip_file)
    url = base_url + zip_file

    # Download if not already present
    if not os.path.exists(zip_path):
        print(f"Downloading {zip_file}...")
        urllib.request.urlretrieve(url, zip_path)
        print(f"Downloaded {zip_file} in {time.time() - start:.1f} seconds")
    else:
        print(f"{zip_file} already exists, skipping download")

    # Extract into PATH
    print(f"Extracting {zip_file}...")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(PATH)
    print(f"Extracted {zip_file} in {time.time() - start:.1f} seconds")

# Total elapsed time
total_elapsed = time.time() - total_start
print(f"\nTotal time: {total_elapsed:.1f} seconds")

"""
**Determine how each image is labeled as benign or malignant.**

We’ll use the `benign_malignant` field for this purpose and first verify that every dataset entry includes this label.
"""

# List unique values for 'benign_malignant' and count missing entries
unique_vals = set()
missing_count = 0

for entry in results:
    clinical = entry.get("metadata", {}).get("clinical", {})
    val = clinical.get("benign_malignant", None)
    if val is None:
        missing_count += 1
    else:
        unique_vals.add(val)

# Print the unique labels found
if unique_vals:
    print(f"Unique 'benign_malignant' values: {', '.join(sorted(unique_vals))}")
else:
    print("No entries possess the 'benign_malignant' parameter.")

# Report how many are missing
if missing_count > 0:
    print(f"{missing_count} entries do not possess the 'benign_malignant' parameter.")

"""**Summary:** A number of records are missing the `benign_malignant` attribute, so we must select an alternative field. The `diagnosis_1` attribute appears suitable for this task; next, we will examine its possible values.

"""

missing_diagnosis_1_values = set()

for entry in results:
    clinical = entry.get("metadata", {}).get("clinical", {})

    if "benign_malignant" not in clinical:
        diag1 = clinical.get("diagnosis_1")
        if diag1:
            missing_diagnosis_1_values.add(diag1)

print(" Unique 'diagnosis_1' values for entries missing 'benign_malignant':")
for value in sorted(missing_diagnosis_1_values):
    print("-", value)

"""**Conclusion:** For records lacking the `benign_malignant` attribute, we will use `diagnosis_1`, which also indicates lesion pathology. Entries where `diagnosis_1` equals “Indeterminate” will be excluded, as they do not provide definitive diagnostic information.

We will construct `lesions.csv` with the following columns:

- **file**: `<isic_id>.jpg`  
- **patient**: `lesion_id`  
- **label**:  
  - `0` for records where `benign_malignant == "benign"`  
  - `1` for records where `benign_malignant == "malignant"`
"""

rows = []
start = time.time()
for result in results:
    try:
        isic_id = result["isic_id"]
        filename = f"{isic_id}.jpg"
        clinical = result["metadata"]["clinical"]
        patient = clinical.get("lesion_id", "unknown")

        benign_malignant = clinical.get("benign_malignant")
        diagnosis_1 = clinical.get("diagnosis_1", "")

        if benign_malignant:
            label = 1 if benign_malignant.lower() == "malignant" else 0
        elif diagnosis_1 == "Benign":
            label = 0
        elif diagnosis_1 == "Malignant":
            label = 1
        else:  # Indeterminate or unknown
            continue

        rows.append({
            "file": filename,
            "patient": patient,
            "label": label
        })

    except Exception as e:
        print(f"Skipped entry {result.get('isic_id', 'UNKNOWN')} due to error: {e}")

# Create DataFrame and write to CSV
df = pd.DataFrame(rows)
df.to_csv("lesions.csv", index=False)

elapsed = time.time() - start
print(f"Took {elapsed:.1f} seconds")

print("Saved lesions.csv with", len(df), "entries.")

"""### Excluding HAM10000 Dataset (Deprecated)

Through detailed investigation, we determined that the HAM10000 dataset is fully subsumed by the ISIC 2018 Task 3 collection, resulting in duplicate images. To avoid redundancy, we have removed HAM10000 from our analysis.

The following code snippet confirms this overlap by comparing the ISIC image IDs with those in the HAM10000 metadata:

import kagglehub
import os
import shutil
from tqdm import tqdm

# Step 1: Download the dataset
path = kagglehub.dataset_download("kmader/skin-cancer-mnist-ham10000")
print("Dataset downloaded to:", path)

# Step 2: Create destination folder
dst_dir = "KAGGLE_IMAGES_ham10000"
os.makedirs(dst_dir, exist_ok=True)

# Step 3: Walk the directory and copy .jpg files
count = 0
for root, _, files in os.walk(path):
    for file in files:
        if file.lower().endswith(".jpg"):
            src_path = os.path.join(root, file)
            dst_path = os.path.join(dst_dir, file)
            shutil.copy2(src_path, dst_path)
            count += 1

print(f"Copied {count} .jpg files into '{dst_dir}'")
meta_src = os.path.join(path, "HAM10000_metadata.csv")
meta_dst = os.path.join(dst_dir, "HAM10000_metadata.csv")
shutil.copy2(meta_src, meta_dst)
print("Copied metadata file to:", dst_dir)

metadata_path = "KAGGLE_IMAGES_ham10000/HAM10000_metadata.csv"
df = pd.read_csv(metadata_path)

metadata_ids = set(df["image_id"])

all_ids_set = set(all_ids)

missing_ids = metadata_ids - all_ids_set

print(f"Found {len(missing_ids)} image_ids in HAM10000 metadata that are not in all_ids:")
for mid in sorted(missing_ids):
    print("-", mid)"

#Stage 2: Data & Preprocessing

**Patient‐wise 70/15/15 split:**  
We randomly assign 70 % of patients to training and split the remaining 30 % equally into validation and test sets, filter the DataFrame accordingly, save each subset to CSV, and confirm sample counts and an overall 81 %/19 % benign/malignant distribution.
"""

df = pd.read_csv("lesions.csv")

unique_patients = df["patient"].unique()

train_patients, temp_patients = train_test_split(
    unique_patients, test_size=0.30, random_state=42
)

# Split temp → 50/50 into val and test (15% each)
val_patients, test_patients = train_test_split(
    temp_patients, test_size=0.50, random_state=42
)

# Create splits by filtering on patient ID
train_df = df[df["patient"].isin(train_patients)].reset_index(drop=True)
val_df = df[df["patient"].isin(val_patients)].reset_index(drop=True)
test_df = df[df["patient"].isin(test_patients)].reset_index(drop=True)

train_df.to_csv("lesions_train.csv", index=False)
val_df.to_csv("lesions_val.csv", index=False)
test_df.to_csv("lesions_test.csv", index=False)

print(f"Train: {len(train_df)} samples")
print(f"Val:   {len(val_df)} samples")
print(f"Test:  {len(test_df)} samples")

label_counts = df["label"].value_counts(normalize=True) * 100
print(f"Overall dataset class distribution:")
print(f"  Benign  (0): {label_counts.get(0, 0):.2f}%")
print(f"  Malignant (1): {label_counts.get(1, 0):.2f}%")

"""Augmentation and pre-processing"""

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(0.1, 0.1, 0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])

])

val_transform = transforms.Compose([
    transforms.CenterCrop(224),
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize([0.5,0.5,0.5],
                         [0.5,0.5,0.5])
])

"""This custom `SkinCancerDataset` class wraps our image DataFrame for PyTorch:

- **`dataframe`**: Pandas DataFrame containing `file`, `patient`, and `label` columns.  
- **`image_dir`**: Directory where the images (`<isic_id>.jpg`) are stored.  
- **`transform`**: A `torchvision.transforms.Compose` object for preprocessing and (optionally) augmentations.  
- **`return_filename`**: If `True`, `__getitem__` returns `(image, label, filename)`, useful for logging .
"""

from torch.utils.data import Dataset

class SkinCancerDataset(Dataset):
    def __init__(self, dataframe, image_dir, transform=None, return_filename=False):
        self.df = dataframe
        self.image_dir = image_dir
        self.transform = transform
        self.return_filename = return_filename

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.image_dir, row["file"])
        label = torch.tensor(row["label"], dtype=torch.float32)
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)

        if self.return_filename:
            return image, label, row["file"]
        else:
            return image, label

"""Wrap `SkinCancerDataset` in a PyTorch `DataLoader`"""

from torch.utils.data import DataLoader

start = time.time()
train_dataset = SkinCancerDataset(train_df, PATH, transform=train_transform)

train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=2
)

elapsed = time.time() - start
print(f"Took {elapsed:.1f} seconds")